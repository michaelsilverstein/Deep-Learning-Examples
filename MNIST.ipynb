{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by sentdex's video series at: https://www.youtube.com/watch?v=PwAGxqrXSCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST\n",
    "mnist = input_data.read_data_sets('/tmp/data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 28**2\n",
    "n_classes = 10\n",
    "n_nodes = [n_features,200,n_classes]\n",
    "batch_size = 100\n",
    "\n",
    "#Define placeholders\n",
    "x = tf.placeholder('float',[None,n_features]) #28x28 images\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def neural_network_model(data,n_nodes):\n",
    "    #Construct a neural network model with ReLU activation functions of with depth of hidden layers lenght(n_nodes) \n",
    "    # where n_nodes details the number of node per layer. (n_nodes[0]=input,...,n_nodes[-1]=output)\n",
    "    n_layers = len(n_nodes)\n",
    "    #Initialize weights vectors\n",
    "    weights = []\n",
    "    biases = []\n",
    "    #Initialize input\n",
    "    layer = data\n",
    "    for l in range(n_layers):\n",
    "        curr_nodes = n_nodes[l]\n",
    "        next_nodes = n_nodes[l+1]\n",
    "        \n",
    "        #Initialize weights for current layer\n",
    "        weights.append(tf.Variable(tf.random_normal([curr_nodes,next_nodes])))\n",
    "        biases.append(tf.Variable(tf.random_normal([next_nodes])))\n",
    "        \n",
    "        #Create connections\n",
    "        # Next layer = activation function(previous layer * weights + biases)\n",
    "        if l == n_layers-2:\n",
    "            #Output\n",
    "            output = tf.matmul(layer,weights[l]) + biases[l]\n",
    "            return output\n",
    "        else:\n",
    "            layer = tf.nn.relu(tf.matmul(layer,weights[l]) + biases[l])\n",
    "\n",
    "def train_neural_network(x,epochs=10):\n",
    "    #Train nn\n",
    "    #Output from nn\n",
    "    prediction = neural_network_model(x,n_nodes)\n",
    "    #Cost of prediction\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y) )\n",
    "    #Backprop\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    #Run session\n",
    "    with tf.Session() as sess:\n",
    "        \"\"\"TRAIN\"\"\"\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            loss = 0\n",
    "            #For each batch\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                #Data and labels\n",
    "                epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _,c = sess.run([optimizer,cost],feed_dict={x:epoch_x,y:epoch_y})\n",
    "                loss += c\n",
    "            print('Epoch: %d out of %d with loss %.3f'%(epoch,epochs,loss))\n",
    "        \n",
    "        \"\"\"TEST\"\"\"\n",
    "        #Calculate accuracy   \n",
    "        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('Accuracy: %.3f'%accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_77:0\", shape=(?, 10), dtype=float32)\n",
      "Epoch: 0 out of 10 with loss 11575.941\n",
      "Epoch: 1 out of 10 with loss 2851.577\n",
      "Epoch: 2 out of 10 with loss 1875.074\n",
      "Epoch: 3 out of 10 with loss 1396.404\n",
      "Epoch: 4 out of 10 with loss 1087.098\n",
      "Epoch: 5 out of 10 with loss 870.263\n",
      "Epoch: 6 out of 10 with loss 709.925\n",
      "Epoch: 7 out of 10 with loss 587.784\n",
      "Epoch: 8 out of 10 with loss 482.822\n",
      "Epoch: 9 out of 10 with loss 408.197\n",
      "Accuracy: 0.935\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
